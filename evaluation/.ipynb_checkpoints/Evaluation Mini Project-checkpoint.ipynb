{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724137931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the evaluation mini-project.\n",
    "    Start by copying your trained/tested POI identifier from\n",
    "    that which you built in the validation mini-project.\n",
    "\n",
    "    This is the second step toward building your POI identifier!\n",
    "\n",
    "    Start by loading/formatting the data...\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "### add more features to features_list!\n",
    "features_list = [\"poi\", \"salary\"]\n",
    "\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "\n",
    "### POI IDENTIFIER\n",
    "from sklearn import cross_validation\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(\n",
    "    features, labels, test_size=0.3, random_state=0)\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "print clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Num of POIs predicted in TEST set\n",
    "print sum(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "# Num of people total in TEST set\n",
    "print len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Find num of true positives\n",
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == 1 and labels_test[i] == 1:\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Find precision & recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score = precision_score(labels_test, pred)\n",
    "recall_score = recall_score(labels_test, pred)\n",
    "print precision_score\n",
    "print recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Find num of true positives part 2 w/ made up data\n",
    "predictions = [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1] \n",
    "true_labels = [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
    "count = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 1 and true_labels[i] == 1:\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Find num of true negatives w/ made up data\n",
    "count = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 0 and true_labels[i] == 0:\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Find num of false positives w/ made up data\n",
    "count = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 1 and true_labels[i] == 0:\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
